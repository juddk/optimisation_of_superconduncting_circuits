{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Zeropi Hamiltonioan via Discretization \n",
    "import scipy.sparse as sps\n",
    "\n",
    "EJ: torch.Tensor\n",
    "EL: torch.Tensor\n",
    "ECJ: torch.Tensor\n",
    "EC: torch.Tensor\n",
    "dEJ: torch.Tensor\n",
    "dCJ: torch.Tensor\n",
    "flux: torch.Tensor\n",
    "ng: float\n",
    "ncut: float\n",
    "truncated_dim: float\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "add(sparse, dense) is not supported. Use add(dense, sparse) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m _sin_theta_m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(sin_theta)\n\u001b[1;32m     62\u001b[0m \u001b[39m#What do the krons do? The partial derivative operators are identical  - why would be chose different N to make them different? \u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m H \u001b[39m=\u001b[39m \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m ECj \u001b[39m*\u001b[39;49m (partial_phi_fd \u001b[39m*\u001b[39;49m partial_phi_bk) \\\n\u001b[1;32m     65\u001b[0m     \u001b[39m+\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m ECs \u001b[39m*\u001b[39;49m ((\u001b[39m1\u001b[39;49mj \u001b[39m*\u001b[39;49m partial_theta_fd) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m) \\\n\u001b[1;32m     66\u001b[0m     \u001b[39m+\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m ECs \u001b[39m*\u001b[39;49m dCj \u001b[39m*\u001b[39;49m partial_phi_fd \u001b[39m*\u001b[39;49m partial_theta_fd \\\n\u001b[1;32m     67\u001b[0m     \u001b[39m-\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m EJ \u001b[39m*\u001b[39;49m _cos_phi \u001b[39m*\u001b[39;49m _cos_theta_adj_m \\\n\u001b[1;32m     68\u001b[0m     \u001b[39m+\u001b[39m EL \u001b[39m*\u001b[39m _phi \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \\\n\u001b[1;32m     69\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m EJ \\\n\u001b[1;32m     70\u001b[0m     \u001b[39m+\u001b[39m EJ \u001b[39m*\u001b[39m dEj \u001b[39m*\u001b[39m _sin_theta_m \u001b[39m*\u001b[39m _sin_phi_adj_m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: add(sparse, dense) is not supported. Use add(dense, sparse) instead."
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sps\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def scipy_sparse_to_torch_sparse(matrix):\n",
    "    \"\"\"Converts a scipy.sparse matrix to a PyTorch sparse tensor.\"\"\"\n",
    "    if not sps.isspmatrix_coo(matrix):\n",
    "        matrix = matrix.tocoo()\n",
    "\n",
    "    values = matrix.data\n",
    "    indices = np.vstack((matrix.row, matrix.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    shape = matrix.shape\n",
    "\n",
    "    return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "\n",
    "ECj = torch.tensor(5., requires_grad=True)\n",
    "ECs = torch.tensor(5., requires_grad=True)\n",
    "dCj = torch.tensor(5., requires_grad=True)\n",
    "dEj = torch.tensor(5., requires_grad=True)\n",
    "EJ = torch.tensor(5., requires_grad=True)\n",
    "ng =1\n",
    "phi_ext = 0.5\n",
    "varphi_ext =0.5\n",
    "\n",
    "Nphi = 100\n",
    "Ntheta = 100\n",
    "\n",
    "eye_Nphi = sps.eye(Nphi)\n",
    "eye_Ntheta = sps.eye(Ntheta)\n",
    "\n",
    "partial_phi_fd = scipy_sparse_to_torch_sparse(sps.kron(eye_Ntheta, sps.diags([-1, 1, 1], [0, 1, -Nphi+1], shape=(Nphi, Nphi))))\n",
    "\n",
    "partial_phi_bk = scipy_sparse_to_torch_sparse(sps.kron(eye_Ntheta, sps.diags([1, -1, -1], [0, -1, Nphi-1], shape=(Nphi, Nphi))))\n",
    "\n",
    "partial_theta_fd = scipy_sparse_to_torch_sparse(sps.kron(eye_Nphi, sps.diags([-1, 1, 1], [0, 1, -Ntheta+1], shape=(Ntheta, Ntheta))))\n",
    "\n",
    "partial_theta_bk = scipy_sparse_to_torch_sparse(sps.kron(eye_Nphi, sps.diags([1, -1, -1], [0, -1, Ntheta-1], shape=(Ntheta, Ntheta))))\n",
    "\n",
    "\n",
    "phi = np.linspace(0, 2 * np.pi, Nphi)\n",
    "cos_phi = np.cos(phi)\n",
    "cos_phi_m = np.diag(cos_phi)\n",
    "sin_phi_adj = np.sin(phi-phi_ext/2)\n",
    "sin_phi_adj_m = np.diag(sin_phi_adj)\n",
    "phi_m = np.diag(phi)\n",
    "_cos_phi = torch.tensor(cos_phi_m)\n",
    "_phi = torch.tensor(phi_m)\n",
    "_sin_phi_adj_m  = torch.tensor(sin_phi_adj_m)\n",
    "\n",
    "theta = np.linspace(0, 2 * np.pi, Ntheta)\n",
    "cos_theta_adj = np.cos(theta-varphi_ext/2)\n",
    "sin_theta = np.sin(theta)\n",
    "cos_theta_adj_m = np.diag(cos_theta_adj)\n",
    "sin_theta_adj_m = np.diag(sin_theta)\n",
    "_cos_theta_adj_m = torch.tensor(cos_theta_adj_m)\n",
    "_sin_theta_m = torch.tensor(sin_theta)\n",
    "\n",
    "#What do the krons do? The partial derivative operators are identical  - why would be chose different N to make them different? \n",
    "\n",
    "H = -2 * ECj * (partial_phi_fd * partial_phi_bk) \\\n",
    "    + 2 * ECs * ((1j * partial_theta_fd - ng) ** 2) \\\n",
    "    + 2 * ECs * dCj * partial_phi_fd * partial_theta_fd \\\n",
    "    - 2 * EJ * _cos_phi * _cos_theta_adj_m \\\n",
    "    + EL * _phi ** 2 \\\n",
    "    + 2 * EJ \\\n",
    "    + EJ * dEj * _sin_theta_m * _sin_phi_adj_m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
