{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys\n",
    "sys.path.append('/Users/judd/Documents/optimisation_of_superconduncting_circuits/core')\n",
    "from fluxonium import Fluxonium \n",
    "import general as general\n",
    "import scqubits as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625494610514317.0\n",
      "0.8974570212084598\n",
      "0.897457005239348\n",
      "0.897456885356036\n",
      "0.8974570052393152\n",
      "1.0000000000000226\n",
      "6509041.996963719\n"
     ]
    }
   ],
   "source": [
    "#Validating T2 Calcs Against SCQUBITS\n",
    "\n",
    "EJ = torch.tensor(14, requires_grad=True, dtype=torch.double)\n",
    "EC = torch.tensor(4.6, requires_grad=True, dtype=torch.double)\n",
    "EL = torch.tensor(0.5, requires_grad=True, dtype=torch.double)\n",
    "flux = torch.tensor(0.5, requires_grad=True, dtype=torch.double)\n",
    "dim = 110\n",
    "\n",
    "\n",
    "fluxonium_auto = Fluxonium(EJ, EC, EL, flux, dim, 'auto_H')\n",
    "fluxonium_create = Fluxonium(EJ, EC, EL, flux, dim, 'create_H')\n",
    "fluxonium_sc = sc.Fluxonium(EJ = EJ.item(), EC = EC.item(), EL = EL.item(), flux = flux.item(),cutoff = dim)\n",
    "\n",
    "print((fluxonium_sc.t1_quasiparticle_tunneling()*general.effective_t1_rate(fluxonium_create, \"t1_quasiparticle_tunneling\").item()))\n",
    "print((fluxonium_sc.t1_charge_impedance()*general.effective_t1_rate(fluxonium_auto , \"t1_charge_impedance\").item()))\n",
    "print((fluxonium_sc.t1_capacitive()*general.effective_t1_rate(fluxonium_auto, \"t1_capacitive\").item()))\n",
    "print((fluxonium_sc.t1_inductive() * general.effective_t1_rate(fluxonium_auto, \"t1_inductive\").item()))\n",
    "print((fluxonium_sc.t1_flux_bias_line() * general.effective_t1_rate(fluxonium_auto , \"t1_flux_bias_line\").item()))\n",
    "print((fluxonium_sc.tphi_1_over_f_cc() * general.effective_tphi_rate(fluxonium_auto , \"tphi_1_over_f_cc\").item()))\n",
    "print((fluxonium_sc.tphi_1_over_f_flux() * general.effective_tphi_rate(fluxonium_auto, \"tphi_1_over_f_flux()\").item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0027]], dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general.t2_rate(fluxonium_create, fluxonium_create.t1_supported_noise_channels(), fluxonium_create.tphi_supported_noise_channels())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: T2: 8.094098612878955e-09, EJ: 16.52220159140853, EL: 3.8741305318935844, EC: 4.60487772526564\n",
      "2: T2: 8.280278900637147e-09, EJ: 16.534038969477393, EL: 3.841330067404866, EC: 4.5816676722827605\n",
      "3: T2: 8.666630362840458e-09, EJ: 16.55153162040369, EL: 3.7927995232917233, EC: 4.547237618986515\n",
      "4: T2: 9.282946426753768e-09, EJ: 16.574375894135947, EL: 3.7293156122381133, EC: 4.5020400383567045\n",
      "5: T2: 1.0178772273252253e-08, EJ: 16.602187190267465, EL: 3.651868746884678, EC: 4.446661765941949\n",
      "6: T2: 1.1430213238358809e-08, EJ: 16.634516302729388, EL: 3.561625664544865, EC: 4.381809002042788\n",
      "7: T2: 1.315087379150966e-08, EJ: 16.670868457123493, EL: 3.459884837346616, EC: 4.308287826381523\n",
      "8: T2: 1.5509017083054253e-08, EJ: 16.710724001812224, EL: 3.3480265898165946, EC: 4.226980256857842\n",
      "9: T2: 1.8754288201244953e-08, EJ: 16.753559492689185, EL: 3.227460498668116, EC: 4.138816314881693\n",
      "10: T2: 2.3259277574767162e-08, EJ: 16.79886777246708, EL: 3.0995732130157627, EC: 4.044743110321568\n",
      "11: T2: 2.9584189645372034e-08, EJ: 16.846175630928133, EL: 2.965680190581614, EC: 3.945692586250051\n",
      "12: T2: 3.857753030546989e-08, EJ: 16.895057771265684, EL: 2.8269848902893715, EC: 3.8425501985223507\n",
      "13: T2: 5.153307629326809e-08, EJ: 16.945146118522416, EL: 2.6845485752496376, EC: 3.7361272972710835\n",
      "14: T2: 7.04353404328159e-08, EJ: 16.99613399886249, EL: 2.5392729268481538, EC: 3.627140053567434\n",
      "15: T2: 9.834585802746547e-08, EJ: 17.04777536153572, EL: 2.3918961049941445, EC: 3.5161971396964455\n",
      "16: T2: 1.4001759448491375e-07, EJ: 17.09987988942784, EL: 2.24300094839422, EC: 3.4037969760360998\n",
      "17: T2: 2.0288723530589755e-07, EJ: 17.15230535166896, EL: 2.0930322578707266, EC: 3.2903335965056426\n",
      "18: T2: 2.9870902505904626e-07, EJ: 17.20494872175176, EL: 1.9423191638448982, EC: 3.1761087393792913\n",
      "19: T2: 4.463054549487181e-07, EJ: 17.257737389623518, EL: 1.7910987094072985, EC: 3.0613471645320085\n",
      "20: T2: 6.76311043264773e-07, EJ: 17.31062136676789, EL: 1.6395377419617172, EC: 2.946212482936364\n",
      "21: T2: 1.0395617235079656e-06, EJ: 17.363566910885538, EL: 1.4877514774420628, EC: 2.830821611064827\n",
      "22: T2: 1.6223215256283879e-06, EJ: 17.41655162421793, EL: 1.3358182185666263, EC: 2.7152568897022533\n",
      "23: T2: 2.5746674427726964e-06, EJ: 17.46956085798299, EL: 1.1837904500718361, EC: 2.599575638802987\n",
      "24: T2: 4.1648778307575845e-06, EJ: 17.52258516600977, EL: 1.0317028968074031, EC: 2.48381736393406\n",
      "25: T2: 6.886616152045258e-06, EJ: 17.575618546954377, EL: 0.8795782219048024, EC: 2.368009025195719\n",
      "26: T2: 1.167628860178618e-05, EJ: 17.628657252561347, EL: 0.7274309833931915, EC: 2.252168812460721\n",
      "27: T2: 2.0367315878011265e-05, EJ: 17.68169898973921, EL: 0.5752703494454458, EC: 2.1363088203366583\n",
      "28: T2: 3.6676122851218916e-05, EJ: 17.734742391243778, EL: 0.4231019477928447, EC: 2.0204369359721044\n",
      "29: T2: 6.849383825490438e-05, EJ: 17.78778666757875, EL: 0.27092911789812557, EC: 1.904558172177357\n",
      "30: T2: 0.00013416227948486806, EJ: 17.840831380587886, EL: 0.20000000298023224, EC: 1.7886756103545933\n",
      "31: T2: 0.00023320717969628742, EJ: 17.89387633858561, EL: 0.20000000298023224, EC: 1.672790730295222\n",
      "32: T2: 0.0003478380981168354, EJ: 17.94692144902488, EL: 0.20000000298023224, EC: 1.5569043027589444\n",
      "33: T2: 0.0005057832760148018, EJ: 17.999966649187225, EL: 0.20000000298023224, EC: 1.4410168928260338\n",
      "34: T2: 0.0006893895377931256, EJ: 18.053011898702447, EL: 0.20000000298023224, EC: 1.3251288961362049\n",
      "35: T2: 0.0008476299950139549, EJ: 18.106057173177785, EL: 0.20000000298023224, EC: 1.2092405743017434\n",
      "36: T2: 0.0009286649169229779, EJ: 18.15910245898579, EL: 0.20000000298023224, EC: 1.0933520883547916\n",
      "37: T2: 0.0009266241812883853, EJ: 18.21214774922456, EL: 0.20000000298023224, EC: 0.9774635288271614\n"
     ]
    }
   ],
   "source": [
    "#Optimisation\n",
    "\n",
    "#FIXED PARAMS\n",
    "dim = 110\n",
    "learn_rate = 1\n",
    "flux = torch.tensor([0.5], requires_grad=True, dtype=torch.double)\n",
    "\n",
    "#VARIABLE PARAMS\n",
    "EJ = torch.rand(1, requires_grad=True, dtype=torch.double)\n",
    "EC = torch.rand(1, requires_grad=True, dtype=torch.double)\n",
    "EL = torch.rand(1, requires_grad=True, dtype=torch.double)\n",
    "flux = torch.tensor([0.5], requires_grad=True, dtype=torch.double)\n",
    "\n",
    "EJ.data = EJ.data * (20 - 2.5) + 2.5\n",
    "EC.data = EC.data * (8 - 1e-3) + 1e-3\n",
    "EL.data = EL.data * (10 - 2e-1) + 2e-1\n",
    "\n",
    "EJ_bounds = [2.5, 150]\n",
    "EC_bounds = [1e-3, 8]\n",
    "EL_bounds = [2e-1, 10]\n",
    "\n",
    "#RECORDING VALUES\n",
    "EJ_vals = [EJ.item()]\n",
    "EC_vals = [EC.item()]\n",
    "EL_vals = [EL.item()]\n",
    "R2_rate = [1e100, 1e99]\n",
    "\n",
    "# GRADIENT DESCENT\n",
    "i = 0\n",
    "while R2_rate[-1] < R2_rate[-2]:\n",
    "    i+=1\n",
    "\n",
    "    fluxonium = Fluxonium(EJ, EC, EL, flux, dim, 'create_H')\n",
    "    R2  = general.t2_rate(fluxonium, fluxonium.t1_supported_noise_channels(), fluxonium.tphi_supported_noise_channels())\n",
    "    R2_rate.append(R2.item())\n",
    "\n",
    "    R2.backward()\n",
    "    with torch.no_grad():\n",
    "        #If paramater value drops below lower bound, it will remain on the lower bound\n",
    "        ##WHY DO WE - the gradient and not add?\n",
    "        EJ.data = EJ - EJ.grad*learn_rate if EJ - EJ.grad*learn_rate > EJ_bounds[0] else torch.tensor(EJ_bounds[0])\n",
    "        EL.data = EL - EL.grad*learn_rate if EL - EL.grad*learn_rate > EL_bounds[0] else torch.tensor(EL_bounds[0])\n",
    "        EC.data = EC - EC.grad*learn_rate if EC - EC.grad*learn_rate > EC_bounds[0] else torch.tensor(EC_bounds[0])\n",
    "    \n",
    "    #RECORDING VALUES FOR PLOT\n",
    "    EJ_vals.append(EJ.item())\n",
    "    EC_vals.append(EC.item())\n",
    "    EL_vals.append(EL.item())\n",
    "\n",
    "    print(f\"{i}: R2: {R2.item()}, EJ: {EJ.item()}, EL: {EL.item()}, EC: {EC.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
