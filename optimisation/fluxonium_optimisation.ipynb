{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys\n",
    "sys.path.append('/Users/judd/Documents/optimisation_of_superconduncting_circuits/core')\n",
    "from fluxonium import Fluxonium \n",
    "import general as general\n",
    "import scqubits as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3575.)\n",
      " /Users/judd/Documents/optimisation_of_superconduncting_circuits/core/general.py: 67"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.6152079701423645e-05"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing H calculations\n",
    "\n",
    "EJ = torch.tensor(10.00, requires_grad=True, dtype=torch.double)\n",
    "EC = torch.tensor(2.5, requires_grad=True, dtype=torch.double)\n",
    "EL = torch.tensor(1.9, requires_grad=True, dtype=torch.double)\n",
    "flux = torch.tensor(0.5, requires_grad=True, dtype=torch.double)\n",
    "dim = 110\n",
    "\n",
    "fluxonium = Fluxonium(EJ, EC, EL, flux, dim, 'auto_H')\n",
    "fluxonium2 = Fluxonium(EJ, EC, EL, flux, dim, 'create_H')\n",
    "\n",
    "general.t2(fluxonium2, fluxonium2.t1_supported_noise_channels(), fluxonium2.tphi_supported_noise_channels()).item()-general.t2(fluxonium, fluxonium.t1_supported_noise_channels(), fluxonium.tphi_supported_noise_channels()).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: By default all methods that involve calculations of the t1 coherence times/rates, return a sum of upward (i.e., excitation), and downward (i.e., relaxation) rates. To change this behavior, parameter total=False can be passed to any t1-related coherence methods. With total=False, only a one-directional transition between levels i and j is used to calculate the required t1 time or rate.\n",
      "See documentation for details.\n",
      "This warning can be disabled by executing:\n",
      "scqubits.settings.T1_DEFAULT_WARNING=False\n",
      "\n",
      " /Users/judd/Documents/optimisation_of_superconduncting_circuits/venv/lib/python3.8/site-packages/scqubits/core/noise.py: 1195"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.310258610751471e+37\n",
      "-4.803852372068363\n",
      "-40847.94101321115\n",
      "-166662.63067793008\n",
      "-7.013040117264538e+21\n",
      "1.792795956134796e-08\n",
      "7.1810870487846104e+16\n"
     ]
    }
   ],
   "source": [
    "#compare my pytorch computations to scqubits\n",
    "\n",
    "fluxonium_sc = sc.Fluxonium(\n",
    "            EJ = EJ.item(),\n",
    "            EC = EC.item(),\n",
    "            EL = EL.item(),\n",
    "            flux = flux.item(),\n",
    "           cutoff = dim)\n",
    "\n",
    "print(fluxonium_sc.t1_quasiparticle_tunneling() - 1/general.effective_t1_rate(fluxonium2 , \"t1_quasiparticle_tunneling\").item())\n",
    "print(fluxonium_sc.t1_charge_impedance() - 1/general.effective_t1_rate(fluxonium2 , \"t1_charge_impedance\").item())\n",
    "print(fluxonium_sc.t1_capacitive() - 1/general.effective_t1_rate(fluxonium2 , \"t1_capacitive\").item())\n",
    "print(fluxonium_sc.t1_inductive() - 1/general.effective_t1_rate(fluxonium2 , \"t1_inductive\").item())\n",
    "print(fluxonium_sc.t1_flux_bias_line() - 1/general.effective_t1_rate(fluxonium2 , \"t1_flux_bias_line\").item())\n",
    "\n",
    "print(fluxonium_sc.tphi_1_over_f_cc() - 1/general.effective_tphi_rate(fluxonium2 , \"tphi_1_over_f_cc\").item())\n",
    "print(fluxonium_sc.tphi_1_over_f_flux() - 1/general.effective_tphi_rate(fluxonium2, \"tphi_1_over_f_flux()\").item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYCLE:  0\n",
      "T =  547180.3712993208 , cost =  1.8275509364954467e-06 , Best T =  547180.3712993208\n",
      "EJ,EC,EL,flux =  5.6555810174774495 5.273421204451998 7.057068975192265 0.5\n",
      "change EJ,EC,EL,flux =  -0.0002992344084575287 0.0013265998923649056 -0.0007514767316623707 224.35943391897402\n",
      "CYCLE:  1\n",
      "T =  547204.4717147045 , cost =  1.8274704460408158e-06 , Best T =  547204.4717147045\n",
      "EJ,EC,EL,flux =  5.655880251885907 5.2720946045596335 7.057820451923927 0.5\n",
      "change EJ,EC,EL,flux =  -0.00029898453451372714 0.0013273186610124649 -0.0007518718354411372 224.3815940593651\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m#autograd on objective function\u001b[39;00m\n\u001b[1;32m     51\u001b[0m cost \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39mT2\n\u001b[0;32m---> 52\u001b[0m cost\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     54\u001b[0m cost_vals\u001b[39m.\u001b[39mappend(cost\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     56\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCYCLE: \u001b[39m\u001b[39m\"\u001b[39m,i)\n",
      "File \u001b[0;32m~/Documents/optimisation_of_superconduncting_circuits/venv/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/optimisation_of_superconduncting_circuits/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TENSORS\n",
    "\n",
    "#INPUT\n",
    "\n",
    "#random values\n",
    "EJ = torch.rand(1, requires_grad=True, dtype=torch.double)\n",
    "EC = torch.rand(1, requires_grad=True, dtype=torch.double)\n",
    "EL = torch.rand(1, requires_grad=True, dtype=torch.double)\n",
    "flux = torch.tensor([0.5], requires_grad=True, dtype=torch.double)\n",
    "\n",
    "EJ.data = EJ.data * (20 - 2.5) + 2.5\n",
    "EC.data = EC.data * (8 - 1e-3) + 1e-3\n",
    "EL.data = EL.data * (10 - 2e-1) + 2e-1\n",
    "\n",
    "# PARAMETERS\n",
    "dim = 110\n",
    "learn_rate = 3e4\n",
    "\n",
    "# BOUNDS\n",
    "EJ_bounds = [2.5, 150]\n",
    "EC_bounds = [1e-3, 8]\n",
    "EL_bounds = [2e-1, 10]\n",
    "flux_bounds = [0,1]\n",
    "\n",
    "# RECORDING VALUES\n",
    "\n",
    "EJ_vals = [EJ.item()]\n",
    "EC_vals = [EC.item()]\n",
    "EL_vals = [EL.item()]\n",
    "cost_vals = []\n",
    "\n",
    "# GRADIENT DESCENT\n",
    "\n",
    "max_T2 = 0\n",
    "\n",
    "for i in range(0,700):\n",
    "\n",
    "    #reinstantiate values\n",
    "    EJ = torch.tensor(EJ.item(), requires_grad=True, dtype=torch.double)\n",
    "    EC = torch.tensor(EC.item(), requires_grad=True, dtype=torch.double)\n",
    "    EL = torch.tensor(EL.item(), requires_grad=True, dtype=torch.double)\n",
    "    flux = torch.tensor(flux.item(), requires_grad=True, dtype=torch.double)\n",
    "    fluxonium = Fluxonium(EJ, EC, EL, flux, dim, 'create_H')\n",
    "\n",
    "    T2 = general.t2(fluxonium, fluxonium.t1_supported_noise_channels(), fluxonium.tphi_supported_noise_channels())\n",
    "\n",
    "    if T2 > max_T2:\n",
    "        max_T2 = T2\n",
    "    \n",
    "    #autograd on objective function\n",
    "    cost = 1/T2\n",
    "    cost.backward()\n",
    "\n",
    "    cost_vals.append(cost.item())\n",
    "\n",
    "    print(\"CYCLE: \",i)\n",
    "    print(\"T = \",T2.item(), \", cost = \", cost.item(), \", Best T = \", max_T2.item())\n",
    "    print(\"EJ,EC,EL,flux = \",EJ.item(),EC.item(),EL.item(),flux.item())\n",
    "    print(\"change EJ,EC,EL,flux = \",EJ.grad.item()*learn_rate,EC.grad.item()*learn_rate,EL.grad.item()*learn_rate,flux.grad.item()*learn_rate)\n",
    "    \n",
    "    #update parameters according to gradient\n",
    "    with torch.no_grad():\n",
    "        # Near the boundary, we project the gradient onto it. This is the typical approach to constraints.\n",
    "        if EJ - EJ.grad*learn_rate > EJ_bounds[0] and EJ.data - EJ.grad*learn_rate < EJ_bounds[1]:\n",
    "            EJ -= EJ.grad*learn_rate\n",
    "        elif EJ - EJ.grad*learn_rate <= EJ_bounds[0]:\n",
    "            EJ += (torch.tensor(EJ_bounds[0]) - EJ)\n",
    "        else:\n",
    "            EJ += (torch.tensor(EJ_bounds[1]) - EJ)\n",
    "        EJ_vals.append(EJ.item())\n",
    "        \n",
    "        if EC - EC.grad*learn_rate > EC_bounds[0] and EC - EC.grad*learn_rate < EC_bounds[1]:\n",
    "            EC -= EC.grad*learn_rate\n",
    "        elif EC - EC.grad*learn_rate <= EC_bounds[0]:\n",
    "            EC += (torch.tensor(EC_bounds[0]) - EC)\n",
    "        else:\n",
    "            EC += (torch.tensor(EC_bounds[1]) - EC)\n",
    "        EC_vals.append(EC.item())\n",
    "        \n",
    "        if EL - EL.grad*learn_rate > EL_bounds[0] and EL - EL.grad*learn_rate < EL_bounds[1]:\n",
    "            EL -= EL.grad*learn_rate\n",
    "        elif EL - EL.grad*learn_rate <= EL_bounds[0]:\n",
    "            EL += (torch.tensor(EL_bounds[0]) - EL)\n",
    "        else:\n",
    "            EL += (torch.tensor(EL_bounds[1]) - EL)\n",
    "        EL_vals.append(EL.item())\n",
    "\n",
    "    EJ.grad = None\n",
    "    EC.grad = None\n",
    "    EL.grad = None\n",
    "    flux.grad = None\n",
    "\n",
    "#append last cost value to cost array\n",
    "\n",
    "fluxonium = Fluxonium(EJ, EC, EL, flux, dim, 'create_H')\n",
    "\n",
    "T2 = general.t2(fluxonium, fluxonium.t1_supported_noise_channels(), fluxonium.tphi_supported_noise_channels())\n",
    "\n",
    "cost = 1/T2\n",
    "print(\"CYCLE: END\")\n",
    "print(\"T = \",T2.item(), \", cost = \", cost.item(), \", Best T = \", max_T2.item())\n",
    "print(\"EJ,EC,EL,flux = \",EJ.item(),EC.item(),EL.item(),flux.item())\n",
    "\n",
    "cost_vals.append(cost.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
